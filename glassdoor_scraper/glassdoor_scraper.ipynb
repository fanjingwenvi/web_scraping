{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "notes:\n",
    "redirect to hongkong if auto controlled web driver\n",
    "list: Salary Estimate, Headquarters, Competitors, time... \n",
    "\n",
    "further: \n",
    "selenium: fill in keyword, initialize driver for every next click, \n",
    "project: scraping from wikipedia \n",
    "\n",
    "reference: https://github.com/arapfaik/scraping-glassdoor-selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "\n",
    "## import urllib.request\n",
    "## from bs4 import BeautifulSoup\n",
    "## from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "## from selenium import webdriver\n",
    "\n",
    "##mm  -*- coding: utf-8 -*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver(chromedriver_path):\n",
    "    '''\n",
    "    Initializes driver, and navigates to URL\n",
    "    parameter: chromedriver_path \n",
    "    return: driver \n",
    "    '''\n",
    "   \n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    ## using user agent \n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    \n",
    "    #makes the driver more 'undetectale'\n",
    "    options.add_argument(\"--disable-blink-features\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    #create the driver \n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    return driver\n",
    "\n",
    "##mm add user agent \n",
    "##mm makes the driver more 'undetectale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs keyword and loc, and bring you to the Job Listings\n",
    "def go_to_listings(keyword, driver, loc):\n",
    "\n",
    "    \n",
    "       # wait for the search bar to appear\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='sc.keyword']\"))\n",
    "        )\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='sc.location']\"))\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # look for search bar field\n",
    "        position_field = driver.find_element_by_xpath(\"//*[@id='sc.keyword']\")\n",
    "        location_field = driver.find_element_by_xpath(\"//*[@id='sc.location']\")\n",
    "        \n",
    "\n",
    "        # fill in with pre-defined data\n",
    "        position_field.clear()\n",
    "        position_field.send_keys(keyword)\n",
    "        \n",
    "        location_field.clear()\n",
    "        location_field.send_keys(loc)\n",
    "\n",
    "        # wait for a little so location gets set\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath(\" //*[@id='HeroSearchButton']\").click()\n",
    "\n",
    "        # close a random popup if it shows up\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='JAModal']/div/div[2]/span\").click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "  \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xout_pop_ups(driver):\n",
    "    \n",
    "    '''\n",
    "    Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    '''\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"selected\").click()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    #X out pop-up\n",
    "    try:\n",
    "        driver.find_element_by_css_selector('[alt=\"Close\"]').click() \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "##mm driver.find_element_by_class_name(\"selected\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_jobs(driver):\n",
    "    try:\n",
    "        if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "                return 'X'\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        print(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1])\n",
    "        if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "                return 'X'\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_listing(driver, job_button):\n",
    "    illstatus = 'Fine'\n",
    "    try:\n",
    "        job_button.click()#You might\n",
    "        \n",
    "    except Exception:\n",
    "        illstatus = 'Ill'\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            job_button.click()\n",
    "            illstatus = 'Illness Corrected'\n",
    "        except Exception:\n",
    "            illstatus = 'Failed'\n",
    "        \n",
    "    return illstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_listing_info(driver, slp_time, verbose):\n",
    "    time.sleep(slp_time)\n",
    "    collected_successfully = False\n",
    "    no_load_time = 0\n",
    "    while not collected_successfully:\n",
    "        #If page has timed out from not-loading, restart the process by clicking first listing\n",
    "\n",
    "        if(no_load_time >= 10):\n",
    "            driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li[1]\").click()\n",
    "\n",
    "            \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='HeroHeaderModule']/div[3]/div[2]/div/div[1]/div[2]/button\")\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            no_load_time +=1\n",
    "        try:\n",
    "            company_name = driver.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "            location = driver.find_element_by_xpath('.//div[@class=\"location\"]').text\n",
    "            job_title = driver.find_element_by_xpath('.//div[contains(@class, \"title\")]').text\n",
    "            job_description = driver.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "            collected_successfully = True\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        salary_estimate = driver.find_element_by_xpath('.//span[@class=\"gray salary\"]').text\n",
    "    except NoSuchElementException:\n",
    "        salary_estimate = -1 #You need to set a \"not found value. It's important.\"\n",
    "    \n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath('.//span[@class=\"rating\"]').text\n",
    "    except NoSuchElementException:\n",
    "        rating = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "    #Printing for debugging\n",
    "    if verbose:\n",
    "        print(\"Job Title: {}\".format(job_title))\n",
    "        print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "        print(\"Job Description: {}\".format(job_description[:500]))\n",
    "        print(\"Rating: {}\".format(rating))\n",
    "        print(\"Company Name: {}\".format(company_name))\n",
    "        print(\"Location: {}\".format(location))\n",
    "\n",
    "    #Going to the Company tab...\n",
    "    #clicking on this:\n",
    "    #<div class=\"tab\" data-tab-type=\"overview\"><span>Company</span></div>\n",
    "    try:\n",
    "        driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "\n",
    "        try:\n",
    "            size = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Size\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            size = -1\n",
    "\n",
    "        try:\n",
    "            founded = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Founded\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            founded = -1\n",
    "\n",
    "        try:\n",
    "            type_of_ownership = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Type\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            type_of_ownership = -1\n",
    "\n",
    "        try:\n",
    "            industry = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Industry\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            industry = -1\n",
    "\n",
    "        try:\n",
    "            sector = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Sector\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            sector = -1\n",
    "\n",
    "        try:\n",
    "            revenue = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Revenue\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            revenue = -1\n",
    "            \n",
    "        try:\n",
    "            easy_apply = (driver.find_element_by_xpath('//*[@id=\"HeroHeaderModule\"]/div[3]/div[2]/div/div[1]/div[1]/button/span').text  == 'Easy Apply')\n",
    "        except NoSuchElementException:\n",
    "            easy_apply = -1\n",
    "\n",
    "    except NoSuchElementException:  #Rarely, some job postings do not have the \"Company\" tab.\n",
    "        size = -1\n",
    "        founded = -1\n",
    "        type_of_ownership = -1\n",
    "        industry = -1\n",
    "        sector = -1\n",
    "        revenue = -1\n",
    "        easy_apply = -1\n",
    "\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Size: {}\".format(size))\n",
    "        print(\"Founded: {}\".format(founded))\n",
    "        print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "        print(\"Industry: {}\".format(industry))\n",
    "        print(\"Sector: {}\".format(sector))\n",
    "        print(\"Revenue: {}\".format(revenue))\n",
    "        print(\"Easy Apply: {}\".format(easy_apply))\n",
    "        print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    jobinfo = ({\"Job Title\" : job_title,\n",
    "    \"Salary Estimate\" : salary_estimate,\n",
    "    \"Job Description\" : job_description,\n",
    "    \"Rating\" : rating,\n",
    "    \"Company Name\" : company_name,\n",
    "    \"Location\" : location,\n",
    "    \"Size\" : size,\n",
    "    \"Founded\" : founded,\n",
    "    \"Type of ownership\" : type_of_ownership,\n",
    "    \"Industry\" : industry,\n",
    "    \"Sector\" : sector,\n",
    "    \"Revenue\" : revenue,\n",
    "    \"Easy Apply\": easy_apply})\n",
    "    \n",
    "    return jobinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose, path, slp_time, loc = ' ', driver = ' '):\n",
    "    \n",
    "    '''\n",
    "    Gathers jobs as a dataframe, scraped from Glassdoor\n",
    "    '''\n",
    "    \n",
    "    count = 0 \n",
    "\n",
    "##    if(loc == ' '):\n",
    "    driver = initialize_driver(path)\n",
    "## 1\n",
    "    url = \"https://www.glassdoor.com/blog/tag/job-search/\"\n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=Data+Scientist&sc.keyword=Data+Scientist&locT=N&locId=96&jobType=\"\n",
    "    url = 'https://www.glassdoor.com/Job/germany-data-scientist-jobs-SRCH_IL.0,7_IN96_KO8,22_IP2.htm'\n",
    "    driver.get(url)\n",
    "    go_to_listings(keyword, driver, loc)\n",
    "## 2 go to the job list   \n",
    "    jobs = []\n",
    "\n",
    "    while len(jobs) < num_jobs:  \n",
    "        \n",
    "        \n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='HeroSearchButton']\"))\n",
    "        )\n",
    "\n",
    "\n",
    "        #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "        Xout_pop_ups(driver)\n",
    "## 3\n",
    "        x = make_sure_jobs(driver)\n",
    "## 4\n",
    "        if(x == 'X'):\n",
    "            break\n",
    "\n",
    "        #Going through each job in this page\n",
    "        time.sleep(1.5)\n",
    "        job_buttons = driver.find_elements_by_css_selector(\"li.jl.react-job-listing.gdGrid\")  #jl for Job Listing. These are the buttons we're going to click.\n",
    "        if(len(job_buttons) <=25):\n",
    "            print(\"JOBS PER PAGE: \" + str(len(job_buttons)))\n",
    "        for job_button in job_buttons: \n",
    "            if len(jobs) >= num_jobs:\n",
    "                print(\"Job Target Reached:\" + str(len(jobs)) + '/' + str(num_jobs))\n",
    "                break\n",
    "\n",
    "            status = click_listing(driver, job_button)\n",
    "## 5\n",
    "            #Weird error pops up here, so I'm on the lookout,\n",
    "            if(status == 'Failed'):\n",
    "                print(status)\n",
    "                break\n",
    "\n",
    "            #append listing data, to total list for that location \n",
    "            jobs.append(collect_listing_info(driver, slp_time, verbose = verbose))\n",
    "## 6\n",
    "        page_num = driver.find_element_by_xpath(\"//*[@id='ResultsFooter']/div[1]\").text\n",
    "        page_num = page_num.split(' ')\n",
    "        if(page_num[1] == page_num[3]):\n",
    "            break\n",
    "        \n",
    "        #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            if(count<=33):\n",
    "                driver.find_element_by_xpath('.//li[@class=\"next\"]//a').click()\n",
    "                count +=1\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(jobs)  #This line converts the dictionary object into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Target Reached:2/2\n"
     ]
    }
   ],
   "source": [
    "keyword = 'Data Scientist'\n",
    "num_jobs = 2\n",
    "verbose = False \n",
    "path = '/Users/violet/Downloads/chromedriver'\n",
    "slp_time = 2.5 \n",
    "loc = 'Germany'\n",
    "driver = ' '\n",
    "data = get_jobs(keyword, num_jobs, verbose, path, slp_time, loc, driver  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('jobs_data_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer CRM (w/m/d)</td>\n",
       "      <td>-1</td>\n",
       "      <td>null\\nExtern\\n\\nEinleitungstext\\n\\nIn einem in...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>dm-drogerie markt\\n4.0</td>\n",
       "      <td>Karlsruhe</td>\n",
       "      <td>10000+ Employees</td>\n",
       "      <td>1973</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Drug &amp; Health Stores</td>\n",
       "      <td>Retail</td>\n",
       "      <td>$5 to $10 billion (USD)</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ETL Entwickler / Data Engineer (d/m/w)</td>\n",
       "      <td>-1</td>\n",
       "      <td>ETL Entwickler / Data Engineer (d/m/w)\\n\\nSeit...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Devk Deutsche Eisenbahn Versicherung Sach- Und...</td>\n",
       "      <td>Cologne</td>\n",
       "      <td>1001 to 5000 Employees</td>\n",
       "      <td>1889</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Insurance Agencies &amp; Brokerages</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Job Title  Salary Estimate  \\\n",
       "0               Data Engineer CRM (w/m/d)               -1   \n",
       "1  ETL Entwickler / Data Engineer (d/m/w)               -1   \n",
       "\n",
       "                                     Job Description Rating  \\\n",
       "0  null\\nExtern\\n\\nEinleitungstext\\n\\nIn einem in...    4.0   \n",
       "1  ETL Entwickler / Data Engineer (d/m/w)\\n\\nSeit...    3.1   \n",
       "\n",
       "                                        Company Name   Location  \\\n",
       "0                             dm-drogerie markt\\n4.0  Karlsruhe   \n",
       "1  Devk Deutsche Eisenbahn Versicherung Sach- Und...    Cologne   \n",
       "\n",
       "                     Size Founded  Type of ownership  \\\n",
       "0        10000+ Employees    1973  Company - Private   \n",
       "1  1001 to 5000 Employees    1889            Unknown   \n",
       "\n",
       "                          Industry     Sector                   Revenue  \\\n",
       "0             Drug & Health Stores     Retail   $5 to $10 billion (USD)   \n",
       "1  Insurance Agencies & Brokerages  Insurance  Unknown / Non-Applicable   \n",
       "\n",
       "   Easy Apply  \n",
       "0          -1  \n",
       "1          -1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
