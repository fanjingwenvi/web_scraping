{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "further: \n",
    "scraping from wikipedia "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jul 10 23:24:20 2020\n",
    "@author: picklesueat\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  2 09:32:36 2020\n",
    "author: Kenarapfaik\n",
    "url: https://github.com/arapfaik/scraping-glassdoor-selenium\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "\n",
    "## import urllib.request\n",
    "## from bs4 import BeautifulSoup\n",
    "## from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "## from selenium import webdriver\n",
    "\n",
    "##mm  -*- coding: utf-8 -*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver(chromedriver_path):\n",
    "    '''\n",
    "    Initializes driver, and navigates to URL\n",
    "    parameter: chromedriver_path \n",
    "    return: driver \n",
    "    '''\n",
    "   \n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    ## using user agent \n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    \n",
    "    #makes the driver more 'undetectale'\n",
    "    options.add_argument(\"--disable-blink-features\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    #create the driver \n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    return driver\n",
    "\n",
    "##mm add user agent \n",
    "##mm makes the driver more 'undetectale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs keyword and loc, and bring you to the Job Listings\n",
    "def go_to_listings(driver, loc):\n",
    "\n",
    "    \n",
    "       # wait for the search bar to appear\n",
    "    element = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='sc.keyword']\"))\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # look for search bar field\n",
    "        position_field = driver.find_element_by_xpath(\"//*[@id='sc.keyword']\")\n",
    "        location_field = driver.find_element_by_xpath(\"//*[@id='sc.location']\")\n",
    "        \n",
    "\n",
    "        # fill in with pre-defined data\n",
    "        position_field.clear()\n",
    "        position_field.send_keys(keyword)\n",
    "        \n",
    "        location_field.clear()\n",
    "        location_field.send_keys(loc)\n",
    "\n",
    "        # wait for a little so location gets set\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath(\" //*[@id='HeroSearchButton']\").click()\n",
    "\n",
    "        # close a random popup if it shows up\n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='JAModal']/div/div[2]/span\").click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "            \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='JAModal']/div/div[2]/span\").click()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "  \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xout_pop_ups(driver):\n",
    "    \n",
    "    '''\n",
    "    Test for the \"Sign Up\" prompt and get rid of it.\n",
    "    '''\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"selected\").click()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    time.sleep(.1)\n",
    "\n",
    "    #X out pop-up\n",
    "    try:\n",
    "        driver.find_element_by_css_selector('[alt=\"Close\"]').click() \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "##mm driver.find_element_by_class_name(\"selected\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_jobs(driver):\n",
    "    try:\n",
    "        if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div[1]/p/span[2]\").text.split(' ' )[1] == 'search'):\n",
    "                return 'X'\n",
    "    except Exception:\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        print(driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1])\n",
    "        if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "            driver.refresh()\n",
    "            time.sleep(5)\n",
    "            if((driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/div[2]/div/div/h4\").text.split(' ' )[1] == 'search')):\n",
    "                return 'X'\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_listing(driver, job_button):\n",
    "    illstatus = 'Fine'\n",
    "    try:\n",
    "        job_button.click()#You might\n",
    "        \n",
    "    except Exception:\n",
    "        illstatus = 'Ill'\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            job_button.click()\n",
    "            illstatus = 'Illness Corrected'\n",
    "        except Exception:\n",
    "            illstatus = 'Failed'\n",
    "        \n",
    "    return illstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_listing_info(driver, slp_time, verbose):\n",
    "    time.sleep(slp_time)\n",
    "    collected_successfully = False\n",
    "    no_load_time = 0\n",
    "    while not collected_successfully:\n",
    "        #If page has timed out from not-loading, restart the process by clicking first listing\n",
    "\n",
    "        if(no_load_time >= 10):\n",
    "            driver.find_element_by_xpath(\"//*[@id='MainCol']/div[1]/ul/li[1]\").click()\n",
    "\n",
    "            \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//*[@id='HeroHeaderModule']/div[3]/div[2]/div/div[1]/div[2]/button\")\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            no_load_time +=1\n",
    "        try:\n",
    "            company_name = driver.find_element_by_xpath('.//div[@class=\"employerName\"]').text\n",
    "            location = driver.find_element_by_xpath('.//div[@class=\"location\"]').text\n",
    "            job_title = driver.find_element_by_xpath('.//div[contains(@class, \"title\")]').text\n",
    "            job_description = driver.find_element_by_xpath('.//div[@class=\"jobDescriptionContent desc\"]').text\n",
    "            collected_successfully = True\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        salary_estimate = driver.find_element_by_xpath('.//span[@class=\"gray salary\"]').text\n",
    "    except NoSuchElementException:\n",
    "        salary_estimate = -1 #You need to set a \"not found value. It's important.\"\n",
    "    \n",
    "    try:\n",
    "        rating = driver.find_element_by_xpath('.//span[@class=\"rating\"]').text\n",
    "    except NoSuchElementException:\n",
    "        rating = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "    #Printing for debugging\n",
    "    if verbose:\n",
    "        print(\"Job Title: {}\".format(job_title))\n",
    "        print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "        print(\"Job Description: {}\".format(job_description[:500]))\n",
    "        print(\"Rating: {}\".format(rating))\n",
    "        print(\"Company Name: {}\".format(company_name))\n",
    "        print(\"Location: {}\".format(location))\n",
    "\n",
    "    #Going to the Company tab...\n",
    "    #clicking on this:\n",
    "    #<div class=\"tab\" data-tab-type=\"overview\"><span>Company</span></div>\n",
    "    try:\n",
    "        driver.find_element_by_xpath('.//div[@class=\"tab\" and @data-tab-type=\"overview\"]').click()\n",
    "\n",
    "        try:\n",
    "            #<div class=\"infoEntity\">\n",
    "            #    <label>Headquarters</label>\n",
    "            #    <span class=\"value\">San Francisco, CA</span>\n",
    "            #</div>\n",
    "            headquarters = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Headquarters\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            headquarters = -1\n",
    "\n",
    "        try:\n",
    "            size = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Size\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            size = -1\n",
    "\n",
    "        try:\n",
    "            founded = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Founded\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            founded = -1\n",
    "\n",
    "        try:\n",
    "            type_of_ownership = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Type\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            type_of_ownership = -1\n",
    "\n",
    "        try:\n",
    "            industry = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Industry\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            industry = -1\n",
    "\n",
    "        try:\n",
    "            sector = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Sector\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            sector = -1\n",
    "\n",
    "        try:\n",
    "            revenue = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Revenue\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            revenue = -1\n",
    "\n",
    "        try:\n",
    "            competitors = driver.find_element_by_xpath('.//div[@class=\"infoEntity\"]//label[text()=\"Competitors\"]//following-sibling::*').text\n",
    "        except NoSuchElementException:\n",
    "            competitors = -1\n",
    "\n",
    "        \n",
    "        try:\n",
    "            easy_apply = (driver.find_element_by_xpath('//*[@id=\"HeroHeaderModule\"]/div[3]/div[2]/div/div[1]/div[1]/button/span').text  == 'Easy Apply')\n",
    "        except NoSuchElementException:\n",
    "            easy_apply = -1\n",
    "\n",
    "    except NoSuchElementException:  #Rarely, some job postings do not have the \"Company\" tab.\n",
    "        headquarters = -1\n",
    "        size = -1\n",
    "        founded = -1\n",
    "        type_of_ownership = -1\n",
    "        industry = -1\n",
    "        sector = -1\n",
    "        revenue = -1\n",
    "        competitors = -1\n",
    "        easy_apply = -1\n",
    "\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Headquarters: {}\".format(headquarters))\n",
    "        print(\"Size: {}\".format(size))\n",
    "        print(\"Founded: {}\".format(founded))\n",
    "        print(\"Type of Ownership: {}\".format(type_of_ownership))\n",
    "        print(\"Industry: {}\".format(industry))\n",
    "        print(\"Sector: {}\".format(sector))\n",
    "        print(\"Revenue: {}\".format(revenue))\n",
    "        print(\"Competitors: {}\".format(competitors))\n",
    "        print(\"Easy Apply: {}\".format(easy_apply))\n",
    "        print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    jobinfo = ({\"Job Title\" : job_title,\n",
    "    \"Salary Estimate\" : salary_estimate,\n",
    "    \"Job Description\" : job_description,\n",
    "    \"Rating\" : rating,\n",
    "    \"Company Name\" : company_name,\n",
    "    \"Location\" : location,\n",
    "    \"Headquarters\" : headquarters,\n",
    "    \"Size\" : size,\n",
    "    \"Founded\" : founded,\n",
    "    \"Type of ownership\" : type_of_ownership,\n",
    "    \"Industry\" : industry,\n",
    "    \"Sector\" : sector,\n",
    "    \"Revenue\" : revenue,\n",
    "    \"Competitors\" : competitors,\n",
    "    \"Easy Apply\": easy_apply})\n",
    "    \n",
    "    return jobinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose, path, slp_time, loc = ' ', driver = ' '):\n",
    "    \n",
    "    '''\n",
    "    Gathers jobs as a dataframe, scraped from Glassdoor\n",
    "    '''\n",
    "    \n",
    "    count = 0 \n",
    "\n",
    "##    if(loc == ' '):\n",
    "    driver = initialize_driver(path)\n",
    "## 1\n",
    "    url = \"https://www.glassdoor.com/blog/tag/job-search/\"\n",
    "    driver.get(url)\n",
    "    go_to_listings(driver,loc)\n",
    "## 2 go to the job list   \n",
    "    jobs = []\n",
    "\n",
    "    while len(jobs) < num_jobs:  \n",
    "\n",
    "        #Let the page load. Change this number based on your internet speed.\n",
    "        #Or, wait until the webpage is loaded, instead of hardcoding it.\n",
    "\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//*[@id='HeroSearchButton']\"))\n",
    "        )\n",
    "\n",
    "\n",
    "        #Test for the \"Sign Up\" prompt and get rid of it.\n",
    "        Xout_pop_ups(driver)\n",
    "## 3\n",
    "        x = make_sure_jobs(driver)\n",
    "## 4\n",
    "        if(x == 'X'):\n",
    "            break\n",
    "\n",
    "        #Going through each job in this page\n",
    "        time.sleep(1.5)\n",
    "        job_buttons = driver.find_elements_by_css_selector(\"li.jl.react-job-listing.gdGrid\")  #jl for Job Listing. These are the buttons we're going to click.\n",
    "        if(len(job_buttons) <=25):\n",
    "            print(\"JOBS PER PAGE: \" + str(len(job_buttons)))\n",
    "        for job_button in job_buttons: \n",
    "            if len(jobs) >= num_jobs:\n",
    "                print(\"Job Target Reached:\" + str(len(jobs)) + '/' + str(num_jobs))\n",
    "                break\n",
    "\n",
    "            status = click_listing(driver, job_button)\n",
    "## 5\n",
    "            #Weird error pops up here, so I'm on the lookout,\n",
    "            if(status == 'Failed'):\n",
    "                print(status)\n",
    "                break\n",
    "\n",
    "            #append listing data, to total list for that location \n",
    "            jobs.append(collect_listing_info(driver, slp_time, verbose = verbose))\n",
    "## 6\n",
    "        page_num = driver.find_element_by_xpath(\"//*[@id='ResultsFooter']/div[1]\").text\n",
    "        page_num = page_num.split(' ')\n",
    "        if(page_num[1] == page_num[3]):\n",
    "            break\n",
    "        \n",
    "        #Clicking on the \"next page\" button\n",
    "        try:\n",
    "            if(count<=33):\n",
    "                driver.find_element_by_xpath('.//li[@class=\"next\"]//a').click()\n",
    "                count +=1\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "\n",
    "    \n",
    "    return pd.DataFrame(jobs)  #This line converts the dictionary object into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Target Reached:10/10\n"
     ]
    }
   ],
   "source": [
    "keyword = 'Data Scientist'\n",
    "num_jobs = 10\n",
    "verbose = False \n",
    "path = '/Users/violet/Downloads/chromedriver'\n",
    "slp_time = 2.5 \n",
    "loc = 'Germany'\n",
    "driver = ' '\n",
    "data = get_jobs(keyword, num_jobs, verbose, path, slp_time, loc, driver  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fake_proxy\n",
      "  Downloading fake_proxy-0.1.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.8 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from fake_proxy) (4.9.1)\n",
      "Requirement already satisfied: requests<3,>=2.22 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from fake_proxy) (2.24.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4<5,>=4.8->fake_proxy) (2.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.22->fake_proxy) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.22->fake_proxy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.22->fake_proxy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/violet/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.22->fake_proxy) (3.0.4)\n",
      "Installing collected packages: fake-proxy\n",
      "Successfully installed fake-proxy-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fake_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
